# Doozy â€” Local RAG Chatbot (PDF + Web Scraping)

Doozy is a local Retrieval-Augmented Generation (RAG) chatbot that can chat over PDF documents and scraped webpages.
It is designed for **local LLMs** served via **Ollama**, but you can easily swap to other local servers if you prefer.

> The chatbot always introduces and refers to itself as **"Doozy"**.

---

## âœ¨ Features
- ðŸ”Ž Ingest one or more PDFs â€” automatically chunked & embedded locally.
- ðŸŒ Scrape one or more URLs (BeautifulSoup) â€” merge with PDF knowledge base.
- ðŸ§  Fast vector search with FAISS.
- ðŸ¤– Talk to a **local** LLM via **Ollama** (`/api/chat` & `/api/embeddings`).
- ðŸ’¬ CLI chat *or* simple Gradio UI (`--ui gradio`).
- ðŸ’¾ On-disk persistence in `./storage` so you can reuse the index later.
- ðŸ” No external APIs required.

---

## ðŸ§± Architecture
```
run.py                # Entry point (CLI or Gradio UI)
rag_core.py           # RAG pipeline: chunking, embeddings, indexing, retrieval, generation
loaders.py            # PDF loader and text cleaners
web_scrape.py         # URL scraping (requests + BeautifulSoup)
requirements.txt      # Python deps
README.md             # This file
storage/              # (auto) FAISS index + chunk metadata
```

---

## âœ… Requirements
- Python 3.9+
- [Ollama](https://ollama.com) running locally at `http://localhost:11434`  
  Pull the models (or let Ollama pull them on first use):
  ```bash
  ollama pull llama3.1:8b-instruct
  ollama pull nomic-embed-text
  ```

> You can switch to other local models by changing CLI flags.

---

## ðŸš€ Quickstart

### 1) Install Python deps
```bash
pip install -r requirements.txt
```

### 2) Start Ollama (if not already)
```bash
ollama serve
```

### 3) Run with PDFs
```bash
python run.py --pdfs path/to/file1.pdf path/to/file2.pdf
```

### 4) Also scrape URLs
```bash
python run.py --pdfs path/to/file.pdf --urls https://example.com https://docs.example.org
```

### 5) Use the Gradio UI
```bash
python run.py --pdfs path/to/file.pdf --ui gradio
```

### 6) Reuse existing index
```bash
python run.py --reuse-index
```

---

## ðŸ”§ Common Flags
```bash
python run.py   --pdfs path/to/a.pdf path/to/b.pdf   --urls https://example.com   --ollama-model llama3.1:8b-instruct   --embed-model nomic-embed-text   --chunk-size 800   --chunk-overlap 150   --k 5   --ui cli
```

---

## ðŸ§ª Example Prompts
- "Summarize the attached PDF."
- "From the website, list the three most important recommendations."
- "Compare the PDF section on security with this URL's security page."

---

## ðŸ”’ Notes
- This system is **local-first** and uses **no external cloud APIs**.
- If your target site is JavaScript-heavy, you can extend `web_scrape.py` to Playwright easily.
- The FAISS index and metadata are written to `./storage/` by default.

---

## ðŸ“¦ Submission
This repository already matches the requested structure:
- `run.py` â€” primary entry point
- `requirements.txt` â€” dependencies
- Additional helper modules under the same root.

Push to a public GitHub repo and you're done. Good luck! âœ¨
